stages:
  - build
  #- test
  #- sonar-check
  - deploy

variables:
  PROJECT_ROOT: "${CI_PROJECT_DIR}"
  FRONTEND_DIR: "${PROJECT_ROOT}/messenger-frontend"
  BACKEND_DIR: "${PROJECT_ROOT}"
  REPORTS_DIR: "${PROJECT_ROOT}/messenger-frontend/ci-reports"
  
  # Maven settings
  #MAVEN_OPTS: "-Dmaven.repo.local=${PROJECT_ROOT}/.m2/repository"
  MAVEN_CLI_OPTS: "--batch-mode --errors --fail-at-end --show-version"
  
  # Node settings
  NODE_VERSION: "18"
  NPM_CI_OPTS: "--no-audit --prefer-offline"
  
  # SonarQube
  SONAR_PROJECT_KEY: "DeepPK_messenger_f896f465-8052-4d8a-bb95-1979ae24fdb5"
  SONAR_USER_HOME: "${PROJECT_ROOT}/.sonar"
  #GIT_DEPTH: "0"
  
  # Miniqube
  #MINIKUBE_IP: "192.168.49.2"
  REGISTRY: "192.168.49.2:30500"
  DOCKER_HOST: tcp://docker-host:2375
  DOCKER_TLS_CERTDIR: ""
  KUBECONFIG: "/root/.kube/config"
  DOCKER_DRIVER: overlay2


cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - .m2/repository
    - target/classes/
    - messenger-frontend/node_modules
    - target/site/jacoco/

 #------------------------- BACKEND -------------------------
backend-build:
 image: maven:3.8.6-openjdk-18
 stage: build
 tags:
   - messenger
 script:
   - cd "${BACKEND_DIR}"
   - mvn ${MAVEN_CLI_OPTS} clean package -DskipTests
 artifacts:
   paths:
     - target/classes/
     - target/*.jar
   expire_in: 1 day

#backend-test:
# image: maven:3.8.6-openjdk-18
# stage: test
# tags:
#   - messenger
# script:
#   - cd "${BACKEND_DIR}"
#   - mvn ${MAVEN_CLI_OPTS} clean verify
#   - ls -la target/site/jacoco/
#   - ls -la target/classes/
#   - mvn surefire-report:report
#   - mkdir -p "${REPORTS_DIR}"
#   - cp target/site/jacoco/jacoco.xml "${REPORTS_DIR}/backend-jacoco.xml"
#   - cp target/surefire-reports/TEST-*.xml "${REPORTS_DIR}/"
# artifacts:
#   paths:
#     - "${REPORTS_DIR}/*.xml"
#     - "target/classes/"
#   reports:
#     junit:
#       - "${REPORTS_DIR}/TEST-*.xml"

# ------------------------- FRONTEND -----------------------
frontend-build:
 image: node:${NODE_VERSION}-alpine
 stage: build
 tags:
   - messenger
 script:
   - cd "${FRONTEND_DIR}"
   - npm ci ${NPM_CI_OPTS}
   - npm run build
 artifacts:
   paths:
     - messenger-frontend/node_modules/
     - messenger-frontend/build/
   expire_in: 1 day

#frontend-test:
# image: node:${NODE_VERSION}-alpine
# stage: test
# tags:
#   - messenger
# variables:
#   CI: "true"
# before_script:
#   - apk add --no-cache libxslt
# script:
#   - cd "${FRONTEND_DIR}"
#   - npm ci ${NPM_CI_OPTS}
#   - npm install jest-junit --save-dev
#   - mkdir -p "${REPORTS_DIR}"
#   - npm test -- \
#     --coverage \
#     --watchAll=false \
#     --reporters=jest-junit \
#     --testResultsProcessor=jest-junit \
#     --outputFile=ci-reports/raw-report.xml \
#     "src/**/*.test.js"
#   - test -f "${REPORTS_DIR}/raw-report.xml" || exit 1
#   - test -f "sonar-transform.xslt" || exit 1
#   - xsltproc "sonar-transform.xslt" "${REPORTS_DIR}/raw-report.xml" > "${REPORTS_DIR}/frontend-junit.xml"
#   - cp coverage/lcov.info "${REPORTS_DIR}/frontend-lcov.info"
# artifacts:
#   paths:
#     - "${REPORTS_DIR}/frontend-lcov.info"
#     - "${REPORTS_DIR}/frontend-junit.xml"
#   reports:
#     junit: "${REPORTS_DIR}/frontend-junit.xml"


bot-build:
  stage: build
  image: python:3.10-alpine
  tags:
    - messenger
  variables:
    BOT_DIR: "${PROJECT_ROOT}/Telegram_bot"
  script:
    - cd "${BOT_DIR}"
    - ls -la "${BOT_DIR}"
    - pip install -r requirements.txt
  artifacts:
    paths:
      - Telegram_bot/
    expire_in: 1 day

# ------------------------- SONARQUBE ANALYSIS -------------------------
#sonar-check:
# stage: sonar-check
# tags:
#   - dep
# image: sonarsource/sonar-scanner-cli:5.0.1
# variables:
#   SONAR_USER_HOME: "/tmp/.sonar"
#   SONAR_SCANNER_OPTS: "-Xmx512m"
# script:
#   - apk add --no-cache libxslt
#   - sonar-scanner -X
#     -Dsonar.nodejs.executable=$(which node)
#     -Dsonar.projectKey=$SONAR_PROJECT_KEY
#     -Dsonar.host.url=$SONAR_HOST_URL
#     -Dsonar.login=$SONAR_TOKEN
#     -Dsonar.coverage.exclusions=**/WebConfig.java,**/SecurityConfiguration.java
#     -Dsonar.javascript.exclusions=**/setupProxy.js,**/setupTests.js
#     -Dsonar.sources=src/main/java,messenger-frontend/src
#     -Dsonar.java.binaries=${PROJECT_ROOT}/target/classes
#     -Dsonar.coverage.jacoco.xmlReportPaths=messenger-frontend/ci-reports/backend-jacoco.xml
#     -Dsonar.javascript.lcov.reportPaths=messenger-frontend/ci-reports/frontend-lcov.info
#     -Dsonar.testExecutionReportPaths=**/target/surefire-reports/TEST-*.xml
#     -Dsonar.testExecutionReportPaths=messenger-frontend/ci-reports/frontend-junit.xml
#     -Dsonar.qualitygate.wait=true
# needs: [ "backend-test", "frontend-test" ]

deploy:
  stage: deploy
  image: docker:24.0
  tags:
    - dep
  services:
    - name: docker:dind
      alias: docker-host
      command: ["--tls=false", "--host=tcp://0.0.0.0:2375"]
  before_script:
    - apk add --no-cache curl kubectl
    - mkdir -p /etc/docker
    - |
      echo '{"insecure-registries":["'${REGISTRY}'"]}' > /etc/docker/daemon.json
      pkill -SIGHUP dockerd || true
      sleep 3
      
      # Проброс портов (если требуется)
      kubectl port-forward -n kube-system service/registry 5000:30500 >/dev/null 2>&1 &
      sleep 5
      
      # Добавляем host.docker.internal для Linux
      if ! grep -q "host.docker.internal" /etc/hosts; then
      echo "`/sbin/ip route | awk '/default/ { print $3 }'` host.docker.internal" >> /etc/hosts
      fi
  script:
    - sleep 5
    - |
      ping -c 3 host.docker.internal
      curl -v http://${REGISTRY}/v2/_catalog || true
      
      # Сборка образов
      docker build -t ${REGISTRY}/messenger:1.0 -f Dockerfile.back .
      docker build -t ${REGISTRY}/frontend:1.0 -f messenger-frontend/Dockerfile.front ./messenger-frontend
      docker build -t ${REGISTRY}/bot:1.0 -f Telegram_bot/Dockerfile.bot ./Telegram_bot
      
      # Публикация образов
      docker push ${REGISTRY}/messenger:1.0
      docker push ${REGISTRY}/frontend:1.0
      docker push ${REGISTRY}/bot:1.0
      
      curl http://${REGISTRY}/v2/_catalog
      
      # Применение манифестов
      kubectl apply -f cloud/cloud-terraform/minicube-manifest/
      
      # Проверка статуса
      kubectl rollout status deployment/messenger-back --timeout=180s
      kubectl rollout status deployment/app --timeout=180s
      kubectl rollout status deployment/bot --timeout=180s
      
      # Финальная проверка
      kubectl get all,ingress -n messenger
      echo "✅ Deployment successful!"
      
      # Дополнительные проверки
      kubectl get pods -o wide -n messenger
      kubectl get services -n messenger
  needs: ["backend-build", "frontend-build", "bot-build"]
  dependencies:
    - backend-build
    - bot-build
    - frontend-build
